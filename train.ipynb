{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import torch\r\n",
    "import time\r\n",
    "import copy\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "from torch.optim.lr_scheduler import OneCycleLR, ReduceLROnPlateau\r\n",
    "import torch.nn.functional as F\r\n",
    "from torchvision.transforms import transforms, InterpolationMode\r\n",
    "from torchvision.datasets import ImageFolder\r\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060 Laptop GPU'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory paths\r\n",
    "base_path = \"D:\\data\\covid_detection\"\r\n",
    "data_path = os.path.join(base_path, \"dataset\")\r\n",
    "train_path = os.path.join(data_path, \"train\")\r\n",
    "val_path = os.path.join(data_path, \"val\")\r\n",
    "test_path = os.path.join(data_path, \"test\")\r\n",
    "model_weights_path = \"D:\\projects\\CovidDetection\\\\trained_model_weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelReadyDataCreator:\r\n",
    "\r\n",
    "  def __init__(self, train_path, val_path, test_path, data_path=None, model_weights_path=None, project_path=None,height=224, width=224, batch_size=4):\r\n",
    "    self.height = height\r\n",
    "    self.width = width\r\n",
    "    self.project_path = project_path\r\n",
    "    self.data_path = data_path\r\n",
    "    self.model_weights_path = model_weights_path\r\n",
    "    self.batch_size = batch_size\r\n",
    "    self.phases = ['train','val','test']\r\n",
    "    self.dirs = {}\r\n",
    "    for phase in self.phases:\r\n",
    "        if phase == 'train':\r\n",
    "            self. dirs[phase] = train_path\r\n",
    "        elif phase == 'val' :\r\n",
    "            self.dirs[phase] = val_path\r\n",
    "        elif phase == 'test':\r\n",
    "            self.dirs[phase] = test_path\r\n",
    "    \r\n",
    "\r\n",
    "    self.image_datasets = {phase : ImageFolder(self.dirs[phase], transform = self.get_transforms()) for phase in self.phases}\r\n",
    "\r\n",
    "    self.data_loaders = {phase : DataLoader(self.image_datasets[phase], batch_size=2, shuffle=True, num_workers=2) for phase in self.phases}\r\n",
    "\r\n",
    "    self.dataset_sizes = {x : len(self.image_datasets[x]) for x in self.phases}\r\n",
    "\r\n",
    "    self.class_names = self.image_datasets[self.phases[0]].classes\r\n",
    "\r\n",
    "    self.num_of_classes = len(self.class_names)\r\n",
    "\r\n",
    "    self.class_to_idx = self.image_datasets[self.phases[0]].class_to_idx\r\n",
    "\r\n",
    "    self.idx_to_class = {val : key for key, val in self.class_to_idx.items()}\r\n",
    "\r\n",
    "\r\n",
    "  def get_model_weight_paths(self):\r\n",
    "    return self.model_weights_path\r\n",
    "\r\n",
    "  def get_class_to_idx(self):\r\n",
    "    return self.class_to_idx\r\n",
    "\r\n",
    "  def get_idx_to_class(self):\r\n",
    "    return self.idx_to_class\r\n",
    "\r\n",
    "  def get_number_of_classes(self):\r\n",
    "    return self.num_of_classes\r\n",
    "    \r\n",
    "  def get_dataset_sizes(self):\r\n",
    "    return self.dataset_sizes\r\n",
    "  \r\n",
    "  def get_class_names(self):\r\n",
    "    return self.class_names\r\n",
    "\r\n",
    "  def get_image_datasets(self): \r\n",
    "    return self.image_datasets\r\n",
    "\r\n",
    "  def get_data_loaders(self):\r\n",
    "    return self.data_loaders\r\n",
    "\r\n",
    "  def get_dirs(self):\r\n",
    "    return self.dirs\r\n",
    "\r\n",
    "  def get_dimension(self):\r\n",
    "    return self.height, self.width\r\n",
    "\r\n",
    "  def get_project_path(self):\r\n",
    "    return self.project_path\r\n",
    "\r\n",
    "  def get_data_path(self):\r\n",
    "    return self.data_path\r\n",
    "\r\n",
    "  def get_transforms(self, grayscale=False, interpolation_method=InterpolationMode.NEAREST):\r\n",
    "    \"\"\"\r\n",
    "    function to return transforms object with all the transformations\r\n",
    "    param 0 : resize height\r\n",
    "    param 1 : resize width\r\n",
    "    param 2 : grayscale image flag\r\n",
    "    param 3 : Interpolation method used while resizing\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    transformation_list = []\r\n",
    "\r\n",
    "    if grayscale : \r\n",
    "      transformation_list.append(transforms.Grayscale(1))\r\n",
    "\r\n",
    "    transformation_list.append(transforms.Resize((self.height,self.width), interpolation=interpolation_method))\r\n",
    "    transformation_list.append(transforms.RandomHorizontalFlip())\r\n",
    "    transformation_list.append(transforms.ToTensor())\r\n",
    "\r\n",
    "    if grayscale :\r\n",
    "      transformation_list.append(transforms.Normalize(mean=[0.5], std=[0.5]))\r\n",
    "    else:\r\n",
    "      transformation_list.append(transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)))\r\n",
    "      \r\n",
    "    return transforms.Compose(transformation_list)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Base Architecture </h2>\r\n",
    "<img src=\"architecture/base.PNG\"  alt = \"base architecture\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4d9c440da251>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mBaseConvNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"baseConvNet\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class BaseConvNet(nn.Module):\r\n",
    "    def __init__(self,model_name=\"baseConvNet\", num_classes = 2):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.model_name = model_name\r\n",
    "        self.num_classes = num_classes\r\n",
    "        # output size of convolution filter\r\n",
    "        # ((w-k+2p)/s) + 1  => w -> image size, k -> kernel, p -> padding, s -> stride\r\n",
    "        \r\n",
    "        # input_shape = (16, 3, 224, 224)\r\n",
    "        self.conv11 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1)\r\n",
    "        self.bn11 = nn.BatchNorm2d(num_features=32)\r\n",
    "        self.conv12 = nn.Conv2d(in_channels=32, out_channels=32,kernel_size=3,padding=1,stride=1)\r\n",
    "        self.bn12 = nn.BatchNorm2d(num_features=32)\r\n",
    "        self.conv13 = nn.Conv2d(in_channels=32,out_channels=32,kernel_size=5, stride=2)\r\n",
    "        self.bn13 = nn.BatchNorm2d(num_features=32)\r\n",
    "        self.dropout1 = nn.Dropout(p=0.4)\r\n",
    "\r\n",
    "        self.conv21 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\r\n",
    "        self.bn21 = nn.BatchNorm2d(num_features=64)\r\n",
    "        self.conv22 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1)\r\n",
    "        self.bn22 = nn.BatchNorm2d(num_features=64)\r\n",
    "        self.conv23 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=2)\r\n",
    "        self.bn23 = nn.BatchNorm2d(num_features=64)\r\n",
    "        self.dropout2 = nn.Dropout(p=0.4)\r\n",
    "\r\n",
    "        self.flat = nn.Flatten()\r\n",
    "        self.fc1 = nn.Linear(64*53*53, 128)\r\n",
    "        self.bn31 = nn.BatchNorm1d(num_features=128)\r\n",
    "        self.dropout3 = nn.Dropout(0.4)\r\n",
    "        self.fc2 = nn.Linear(in_features=128,out_features=2)\r\n",
    "        \r\n",
    "\r\n",
    "    # Feed forward function\r\n",
    "    def forward(self,image):\r\n",
    "        bs, c, h, w = image.size()\r\n",
    "        output = F.relu(self.bn11(self.conv11(image)))  # shape = (bs, 32, 224, 224)\r\n",
    "        output = F.relu(self.bn12(self.conv12(output))) # shape = (bs, 32, 224, 224)\r\n",
    "        output = F.relu(self.bn13(self.conv13(output))) # shape = (bs, 32, 110, 110)\r\n",
    "        output = self.dropout1(output) # shape = (bs, 32, 110, 110)\r\n",
    "\r\n",
    "        output = F.relu(self.bn21(self.conv21(output))) # shape = (bs, 64, 110, 110)\r\n",
    "        output = F.relu(self.bn22(self.conv22(output))) # shape = (16, 64, 110, 110)\r\n",
    "        output = F.relu(self.bn23(self.conv23(output))) # shape = (16, 64, 53, 53)\r\n",
    "        output = self.dropout2(output) # shape = (16, 64, 53, 53)\r\n",
    "\r\n",
    "        # output = self.flat(output)\r\n",
    "        # or we can directly use output = nn.Flatten()(output)\r\n",
    "        output = output.view(bs,-1) # shape = (bs, 179776)\r\n",
    "        output = self.bn31(self.fc1(output)) # shape (bs, 128)\r\n",
    "        output = self.dropout3(output) # shape (bs, 128)\r\n",
    "        output = self.fc2(output) # shape (bs, 2)\r\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1605632])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn((16, 3, 224, 224))\r\n",
    "conv11 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1)\r\n",
    "m = conv11(input)\r\n",
    "m = m.view(16,-1)\r\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ready_data_creator = ModelReadyDataCreator(train_path, val_path, test_path, data_path, model_weights_path)\r\n",
    "data_loader = model_ready_data_creator.get_data_loaders()\r\n",
    "dataset_sizes = model_ready_data_creator.get_dataset_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseConvNet(num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\r\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "Train loss : 0.0006 Accuracy : 0.7500\n",
      "Eval loss : 0.0296 Accuracy : 0.8500\n",
      "Saving weights for 0 epoch\n",
      "Epoch 1/10\n",
      "Train loss : 0.0051 Accuracy : 0.7276\n",
      "Eval loss : 0.0064 Accuracy : 0.9250\n",
      "Saving weights for 1 epoch\n",
      "Epoch 2/10\n",
      "Train loss : 0.0007 Accuracy : 0.7788\n",
      "Eval loss : 0.0111 Accuracy : 0.9000\n",
      "Epoch 3/10\n",
      "Train loss : 0.0066 Accuracy : 0.6987\n",
      "Eval loss : 0.0224 Accuracy : 0.8250\n",
      "Epoch 4/10\n",
      "Train loss : 0.0029 Accuracy : 0.6987\n",
      "Eval loss : 0.0037 Accuracy : 0.9250\n",
      "Epoch 5/10\n",
      "Train loss : 0.0022 Accuracy : 0.7019\n",
      "Eval loss : 0.0096 Accuracy : 0.8250\n",
      "Epoch 6/10\n",
      "Train loss : 0.0010 Accuracy : 0.7019\n",
      "Eval loss : 0.0164 Accuracy : 0.8500\n",
      "Epoch 7/10\n",
      "Train loss : 0.0016 Accuracy : 0.7019\n",
      "Eval loss : 0.0136 Accuracy : 0.9250\n",
      "Epoch 8/10\n",
      "Train loss : 0.0054 Accuracy : 0.7115\n",
      "Eval loss : 0.0049 Accuracy : 0.9000\n",
      "Epoch 9/10\n",
      "Train loss : 0.0061 Accuracy : 0.7340\n",
      "Eval loss : 0.0081 Accuracy : 0.9000\n",
      "Training complete in 2m 17s\n",
      "Best validation Accuracy: 0.925000\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\r\n",
    "best_model_weights = copy.deepcopy(model.state_dict())\r\n",
    "best_acc = 0.0\r\n",
    "num_epochs = 10\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    print('Epoch {}/{}'.format(epoch,num_epochs))\r\n",
    "    # Training a model\r\n",
    "    model.train()\r\n",
    "    \r\n",
    "    current_train_loss = 0.0\r\n",
    "    currect_train_corrects = 0\r\n",
    "\r\n",
    "    with torch.set_grad_enabled(True):\r\n",
    "\r\n",
    "        for inputs, labels in data_loader['train']:\r\n",
    "            \r\n",
    "            if torch.cuda.is_available():\r\n",
    "                inputs = inputs.to(device)\r\n",
    "                labels = labels.to(device)\r\n",
    "\r\n",
    "            outputs = model(inputs)\r\n",
    "\r\n",
    "            loss = loss_function(outputs,labels)\r\n",
    "\r\n",
    "            max_element, preds = torch.max(outputs,1)\r\n",
    "\r\n",
    "            optimizer.zero_grad()\r\n",
    "\r\n",
    "            loss.backward()\r\n",
    "\r\n",
    "            optimizer.step()\r\n",
    "\r\n",
    "            current_train_loss = loss.cpu().data * inputs.size(0)\r\n",
    "\r\n",
    "            currect_train_corrects += int(torch.sum(preds == labels.data))\r\n",
    "\r\n",
    "    train_epoch_loss = current_train_loss/dataset_sizes['train']\r\n",
    "    train_epoch_accuracy = currect_train_corrects/dataset_sizes['train']\r\n",
    "\r\n",
    "    print('Train loss : {:.4f} Accuracy : {:.4f}'.format(train_epoch_loss, train_epoch_accuracy))\r\n",
    "\r\n",
    "    # Evaluating on testing val data\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    current_eval_loss = 0.0\r\n",
    "    current_eval_corrects = 0\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "\r\n",
    "        for inputs, labels in data_loader['val']:\r\n",
    "\r\n",
    "            if torch.cuda.is_available():\r\n",
    "                inputs = inputs.to(device)\r\n",
    "                labels = labels.to(device)\r\n",
    "\r\n",
    "                outputs = model(inputs)\r\n",
    "                _,preds = torch.max(outputs,1)\r\n",
    "                loss = loss_function(outputs, labels)\r\n",
    "\r\n",
    "                current_eval_loss = loss.cpu().data * inputs.size(0)\r\n",
    "                current_eval_corrects += int(torch.sum(preds == labels.data))\r\n",
    "\r\n",
    "    val_epoch_loss = current_eval_loss/dataset_sizes['val']\r\n",
    "    val_epoch_accuracy = current_eval_corrects/dataset_sizes['val']\r\n",
    "\r\n",
    "    print('Eval loss : {:.4f} Accuracy : {:.4f}'.format(val_epoch_loss,val_epoch_accuracy))\r\n",
    "    \r\n",
    "    if val_epoch_accuracy > best_acc:\r\n",
    "        best_model_weights = copy.deepcopy(model.state_dict())\r\n",
    "        best_acc = val_epoch_accuracy\r\n",
    "        print(f'Saving weights for {epoch} epoch')\r\n",
    "        checkpoint_name = f\"weight_{epoch}.pt\"\r\n",
    "        PATH = os.path.join(current_model_weight_path, checkpoint_name)\r\n",
    "        torch.save({'state_dict': model.state_dict(),\r\n",
    "                    'optimizer_state_dict' : optimizer.state_dict(),\r\n",
    "                    'epoch' : epoch\r\n",
    "                    }, \r\n",
    "                    PATH)\r\n",
    "\r\n",
    "end_time = time.time() - since\r\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(end_time // 60, end_time % 60))\r\n",
    "print('Best validation Accuracy: {:4f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, data_loader, optimizer, scheduler, loss_function, device=torch.device(\"cuda\")):\r\n",
    "  \"\"\"\r\n",
    "  function to train model\r\n",
    "  :param model : model to train\r\n",
    "  :data_loader : data_loader of training phase\r\n",
    "  :scheduler : scheduler\r\n",
    "  :loss_function : loss function\r\n",
    "  :device : device on which we need to train\r\n",
    "  :return: tuple(running loss, current currect prediction)\r\n",
    "  \"\"\"\r\n",
    "  print('Train mode')\r\n",
    "  # set training mode : It changed the behaviour of some layers like batch normalization use batch data not saved statistics(it happens in val & test phase), droupout is enabled\r\n",
    "  model.train()\r\n",
    "  \r\n",
    "  current_loss = 0.0\r\n",
    "  current_corrects = 0\r\n",
    "  \r\n",
    "  # The torch.set_grad_enabled line of code makes sure to clear the intermediate values for evaluation, which are needed to backpropagate during training\r\n",
    "  with torch.set_grad_enabled(True):\r\n",
    "    \r\n",
    "    # print(\"Iterating through data\")\r\n",
    "    for inputs, labels in data_loader :\r\n",
    "      # moving the inputs and labels to device passed in function\r\n",
    "      inputs = inputs.to(device)\r\n",
    "      labels = labels.to(device)\r\n",
    "\r\n",
    "      outputs = model(inputs)\r\n",
    "      max_element,preds = torch.max(outputs,1)\r\n",
    "      loss = loss_function(outputs, labels)\r\n",
    "\r\n",
    "      # setting zero to all gradients before gradient calculation/backpropogation\r\n",
    "      optimizer.zero_grad() \r\n",
    "\r\n",
    "      # Do backpropagation/calculate gradient\r\n",
    "      # Backward pass: compute gradient of the loss with respect to model\r\n",
    "      loss.backward()\r\n",
    "\r\n",
    "      # update weights/parameters\r\n",
    "      optimizer.step()\r\n",
    "\r\n",
    "      if scheduler:\r\n",
    "        # If you don’t call it, the learning rate won’t be changed and stays at the initial value.\r\n",
    "        # should call scheduler.step() after the optimizer.step() \r\n",
    "        scheduler.step()\r\n",
    "\r\n",
    "      # It's because the loss given by CrossEntropy or other loss functions is divided by the number of elements i.e. the reduction parameter is mean by default. \r\n",
    "      # torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\r\n",
    "      # Hence, loss.item() contains the loss of entire mini-batch, but divided by the batch size. That's why loss.item() is multiplied with batch size, given by inputs.size(0), while calculating running_loss.\r\n",
    "      # here we'll get mean of loss of entire batch using loss.item() that's why we are multiplying it with batch_ size to get current loss.\r\n",
    "      current_loss = loss.item() * inputs.size(0)\r\n",
    "      current_corrects += torch.sum(preds == labels.data)\r\n",
    "\r\n",
    "  return current_loss, current_corrects\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(model, data_loader, loss_function, device=torch.device(\"cuda\")):\r\n",
    "  \"\"\"\r\n",
    "  function to validate model\r\n",
    "  :param model : model to train\r\n",
    "  :data_loader : data_loader of training phase\r\n",
    "  :scheduler : scheduler\r\n",
    "  :loss_function : loss function\r\n",
    "  :device : device on which we need to train\r\n",
    "  :return: tuple(running loss, current currect prediction)\r\n",
    "  \"\"\"\r\n",
    "  print('Validation mode')\r\n",
    "  # dropout is disabled and so is replaced with a no op. Similarly, bn should use saved statistics instead of batch data \r\n",
    "  model.eval()\r\n",
    "\r\n",
    "  current_loss = 0.0\r\n",
    "  current_corrects = 0\r\n",
    "\r\n",
    "  # impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script).\r\n",
    "  # it is same as with torch.set_grad_enabled(False):\r\n",
    "  with torch.no_grad():\r\n",
    "\r\n",
    "    # print(\"Iterating through data\")\r\n",
    "    for inputs, labels in data_loader :\r\n",
    "\r\n",
    "      # moving the inputs and labels to device passed in function\r\n",
    "      inputs = inputs.to(device)\r\n",
    "      labels = labels.to(device)\r\n",
    "\r\n",
    "      outputs = model(inputs)\r\n",
    "      _,preds = torch.max(outputs,1)\r\n",
    "      loss = loss_function(outputs, labels)\r\n",
    "\r\n",
    "      current_loss = loss.item() * inputs.size(0)\r\n",
    "      current_corrects += torch.sum(preds == labels.data)\r\n",
    "    \r\n",
    "  return current_loss, current_corrects\r\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_load_checkpoint(checkpoint_path, model, optimizer):\r\n",
    "  \"\"\"\r\n",
    "  function to load checkpoint\r\n",
    "  :param checkpoint_path: checkpoint path\r\n",
    "  :param model: model \r\n",
    "  :param optimizer: optimizer\r\n",
    "  \"\"\"\r\n",
    "  checkpoint = torch.load(checkpoint_path)\r\n",
    "  model.load_state_dict(checkpoint['state_dict'])\r\n",
    "  optimizer.load_state_dict(checkpoint['optimizer'])\r\n",
    "  return model, optimizer, checkpoint['epoch']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, loss_function, optimizer, scheduler, model_ready_data_creator, another_scheduler = None, num_epochs = 50, start_epoch = 1):\r\n",
    "\r\n",
    "  since = time.time()\r\n",
    "  data_loader = model_ready_data_creator.get_data_loaders()\r\n",
    "  dataset_sizes = model_ready_data_creator.get_dataset_sizes()\r\n",
    "  model_weights_path = model_ready_data_creator.get_model_weight_paths()\r\n",
    "  idx_to_class = model_ready_data_creator.get_idx_to_class()\r\n",
    "  class_to_idx = model_ready_data_creator.get_class_to_idx()\r\n",
    "\r\n",
    "  current_model_weight_path = os.path.join(model_weights_path, model.model_name)\r\n",
    "  if not os.path.exists(current_model_weight_path):\r\n",
    "    os.mkdir(current_model_weight_path)\r\n",
    "\r\n",
    "  train_loss_values = []\r\n",
    "  val_loss_values = []\r\n",
    "\r\n",
    "  train_accuracy_values = []\r\n",
    "  val_accuracy_values = []\r\n",
    "\r\n",
    "  best_model_weights = copy.deepcopy(model.state_dict())\r\n",
    "  best_acc = 0.0\r\n",
    "\r\n",
    "  for epoch in range(start_epoch, num_epochs+1) : \r\n",
    "    print('Epoch {}/{}'.format(epoch,num_epochs))\r\n",
    "    print('-'*150)\r\n",
    "\r\n",
    "    train_loss, train_corrects = train_loop(model, data_loader['train'], optimizer, scheduler, loss_function, device)\r\n",
    "\r\n",
    "    # here we are taking running loss and divide it by whole dataset_size to get the average/mean loss\r\n",
    "    train_epoch_loss = train_loss/dataset_sizes['train']\r\n",
    "    # calculating accuracy by dividing total_corrects/dataset_size\r\n",
    "    train_epoch_accuracy = train_corrects.double()/dataset_sizes['train']\r\n",
    "    print('Train Loss: {:.4f} Accuracy : {:.4f}'.format(train_epoch_loss, train_epoch_accuracy))\r\n",
    "    print('-'*50)\r\n",
    "\r\n",
    "    train_loss_values.append(train_epoch_loss)\r\n",
    "    train_accuracy_values.append(train_epoch_accuracy)\r\n",
    "\r\n",
    "    validation_loss, validation_corrects = eval_loop(model, data_loader['val'], loss_function, device)\r\n",
    "    validation_epoch_loss = validation_loss/dataset_sizes['val']\r\n",
    "    validation_epoch_accuracy = validation_corrects.double()/dataset_sizes['val']\r\n",
    "    print('Validation Loss : {:.4f} Accuracy : {:.4f}'.format(validation_epoch_loss, validation_epoch_accuracy))\r\n",
    "\r\n",
    "    val_loss_values.append(validation_epoch_loss)\r\n",
    "    val_accuracy_values.append(validation_epoch_accuracy)\r\n",
    "    if another_scheduler:\r\n",
    "      another_scheduler.step(validation_epoch_loss)\r\n",
    "\r\n",
    "    if validation_epoch_accuracy > best_acc : \r\n",
    "        best_model_weights = copy.deepcopy(model.state_dict())\r\n",
    "        best_acc = validation_epoch_accuracy\r\n",
    "        print(f'Saving weights for {epoch} epoch')\r\n",
    "        checkpoint_name = f\"weight_{epoch}.tar\"\r\n",
    "        PATH = os.path.join(current_model_weight_path, checkpoint_name)\r\n",
    "        torch.save({'state_dict': model.state_dict(),\r\n",
    "                    'optimizer_state_dict' : optimizer.state_dict(),\r\n",
    "                    'epoch' : epoch,\r\n",
    "                    'class_to_idx': class_to_idx\r\n",
    "                    }, \r\n",
    "                    PATH)\r\n",
    "        \r\n",
    "    print()\r\n",
    "\r\n",
    "  checkpoint_name = f\"final_weight_{epoch}.tar\"\r\n",
    "  PATH = os.path.join(current_model_weight_path, checkpoint_name)\r\n",
    "  torch.save({'model': model,\r\n",
    "              'state_dict': best_model_weights,   \r\n",
    "              'class_to_idx': class_to_idx,\r\n",
    "              'optimizer_state_dict' : optimizer.state_dict(),\r\n",
    "              'epoch' : epoch\r\n",
    "              }, \r\n",
    "              PATH)\r\n",
    "  \r\n",
    "  time_since = time.time() - since\r\n",
    "  print('Training complete in {:.0f}m {:.0f}s'.format(time_since // 60, time_since % 60))\r\n",
    "  print('Best validation Accuracy: {:4f}'.format(best_acc))\r\n",
    "  # Now we'll load in the best model weights and return it\r\n",
    "  model.load_state_dict(best_model_weights)\r\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ready_data_creator = ModelReadyDataCreator(train_path, val_path, test_path, data_path, model_weights_path)\r\n",
    "model = BaseConvNet(model_name=\"baseConvNet\",num_classes=model_ready_data_creator.get_number_of_classes())\r\n",
    "model = model.to(device)\r\n",
    "loss_function = nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "epochs = 50 \r\n",
    "lr = 1e-3\r\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.1)\r\n",
    "num_steps = len(model_ready_data_creator.get_data_loaders()['train'])\r\n",
    "start_epoch = 1\r\n",
    "\r\n",
    "# if we want to resume training then set below flag True and provide checkpoint_name and path\r\n",
    "resume_training = False\r\n",
    "if resume_training:\r\n",
    "  model_weights_path = model_ready_data_creator.get_model_weight_paths()\r\n",
    "  #change here\r\n",
    "  current_model_weight_path = os.path.join(model_weights_path, \"baseConvNet\")\r\n",
    "  #change here\r\n",
    "  checkpoint_name = f\"weight_5.pt\"\r\n",
    "  checkpoint_path = os.path.join(current_model_weight_path, checkpoint_name)\r\n",
    "\r\n",
    "  model, optimizer, start_epoch = training_load_checkpoint(checkpoint_path, model, optimizer)\r\n",
    "\r\n",
    "one_cycle_scheduler = OneCycleLR(optimizer, max_lr=lr, epochs=epochs, steps_per_epoch=num_steps)\r\n",
    "reduce_lr_scheduler = ReduceLROnPlateau(optimizer,verbose=True,factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0099 Accuracy : 0.7436\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0171 Accuracy : 0.9500\n",
      "Saving weights for 1 epoch\n",
      "\n",
      "Epoch 2/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0063 Accuracy : 0.7115\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0346 Accuracy : 0.9500\n",
      "\n",
      "Epoch 3/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0002 Accuracy : 0.7179\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0128 Accuracy : 0.8250\n",
      "\n",
      "Epoch 4/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0046 Accuracy : 0.7083\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0217 Accuracy : 0.9250\n",
      "\n",
      "Epoch 5/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0026 Accuracy : 0.6122\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0241 Accuracy : 0.9000\n",
      "\n",
      "Epoch 6/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0054 Accuracy : 0.6282\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0279 Accuracy : 0.9500\n",
      "\n",
      "Epoch 7/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0050 Accuracy : 0.6859\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0180 Accuracy : 0.9000\n",
      "\n",
      "Epoch 8/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0015 Accuracy : 0.6282\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0230 Accuracy : 0.9500\n",
      "\n",
      "Epoch 9/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0016 Accuracy : 0.6987\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0271 Accuracy : 0.9250\n",
      "\n",
      "Epoch 10/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0022 Accuracy : 0.7372\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0033 Accuracy : 0.7500\n",
      "\n",
      "Epoch 11/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0013 Accuracy : 0.6859\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0203 Accuracy : 0.9000\n",
      "\n",
      "Epoch 12/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0043 Accuracy : 0.6955\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0188 Accuracy : 0.9000\n",
      "\n",
      "Epoch 13/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0064 Accuracy : 0.7436\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0132 Accuracy : 0.8500\n",
      "\n",
      "Epoch 14/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0044 Accuracy : 0.7212\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0259 Accuracy : 0.6750\n",
      "\n",
      "Epoch 15/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0022 Accuracy : 0.6987\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0362 Accuracy : 0.8500\n",
      "\n",
      "Epoch 16/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0048 Accuracy : 0.6891\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0240 Accuracy : 0.8500\n",
      "\n",
      "Epoch 17/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0034 Accuracy : 0.7115\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0329 Accuracy : 0.8250\n",
      "\n",
      "Epoch 18/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0022 Accuracy : 0.7436\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0278 Accuracy : 0.9000\n",
      "\n",
      "Epoch 19/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0048 Accuracy : 0.6923\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0279 Accuracy : 0.7250\n",
      "\n",
      "Epoch 20/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0046 Accuracy : 0.7051\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0313 Accuracy : 0.8750\n",
      "\n",
      "Epoch 21/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0031 Accuracy : 0.7276\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0269 Accuracy : 0.8750\n",
      "Epoch    21: reducing learning rate of group 0 to 9.2908e-05.\n",
      "\n",
      "Epoch 22/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0034 Accuracy : 0.7244\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0277 Accuracy : 0.8750\n",
      "\n",
      "Epoch 23/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0034 Accuracy : 0.6987\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0340 Accuracy : 0.3750\n",
      "\n",
      "Epoch 24/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0050 Accuracy : 0.4519\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0367 Accuracy : 0.5000\n",
      "\n",
      "Epoch 25/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0042 Accuracy : 0.6859\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0275 Accuracy : 0.9250\n",
      "\n",
      "Epoch 26/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0029 Accuracy : 0.7404\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0286 Accuracy : 0.8750\n",
      "\n",
      "Epoch 27/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0041 Accuracy : 0.7500\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0333 Accuracy : 0.9000\n",
      "\n",
      "Epoch 28/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0048 Accuracy : 0.7115\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0284 Accuracy : 0.9000\n",
      "\n",
      "Epoch 29/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0041 Accuracy : 0.6795\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0253 Accuracy : 0.9000\n",
      "\n",
      "Epoch 30/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0034 Accuracy : 0.7083\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0300 Accuracy : 0.8500\n",
      "\n",
      "Epoch 31/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0048 Accuracy : 0.7244\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0172 Accuracy : 0.8250\n",
      "\n",
      "Epoch 32/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0049 Accuracy : 0.7340\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0321 Accuracy : 0.8500\n",
      "Epoch    32: reducing learning rate of group 0 to 5.2215e-05.\n",
      "\n",
      "Epoch 33/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0042 Accuracy : 0.7308\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0369 Accuracy : 0.8250\n",
      "\n",
      "Epoch 34/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0023 Accuracy : 0.7083\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0224 Accuracy : 0.8250\n",
      "\n",
      "Epoch 35/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0028 Accuracy : 0.7596\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0360 Accuracy : 0.8000\n",
      "\n",
      "Epoch 36/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0045 Accuracy : 0.7276\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0186 Accuracy : 0.8750\n",
      "\n",
      "Epoch 37/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0025 Accuracy : 0.7212\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0212 Accuracy : 0.8750\n",
      "\n",
      "Epoch 38/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0046 Accuracy : 0.7372\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0190 Accuracy : 0.8500\n",
      "\n",
      "Epoch 39/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0025 Accuracy : 0.7564\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0444 Accuracy : 0.8500\n",
      "\n",
      "Epoch 40/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0046 Accuracy : 0.6987\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0149 Accuracy : 0.8750\n",
      "\n",
      "Epoch 41/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0021 Accuracy : 0.7051\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0285 Accuracy : 0.8750\n",
      "\n",
      "Epoch 42/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0026 Accuracy : 0.6987\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0192 Accuracy : 0.8500\n",
      "\n",
      "Epoch 43/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0025 Accuracy : 0.7051\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0235 Accuracy : 0.8750\n",
      "Epoch    43: reducing learning rate of group 0 to 9.5326e-06.\n",
      "\n",
      "Epoch 44/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0047 Accuracy : 0.7212\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0250 Accuracy : 0.9000\n",
      "\n",
      "Epoch 45/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0049 Accuracy : 0.7083\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0225 Accuracy : 0.9000\n",
      "\n",
      "Epoch 46/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0042 Accuracy : 0.6923\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0228 Accuracy : 0.8500\n",
      "\n",
      "Epoch 47/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0023 Accuracy : 0.7051\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0261 Accuracy : 0.8500\n",
      "\n",
      "Epoch 48/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0022 Accuracy : 0.7724\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0166 Accuracy : 0.9000\n",
      "\n",
      "Epoch 49/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0047 Accuracy : 0.7660\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0441 Accuracy : 0.8750\n",
      "\n",
      "Epoch 50/50\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train mode\n",
      "Train Loss: 0.0053 Accuracy : 0.7115\n",
      "--------------------------------------------------\n",
      "Validation mode\n",
      "Validation Loss : 0.0239 Accuracy : 0.9000\n",
      "\n",
      "Training complete in 8m 1s\n",
      "Best validation Accuracy: 0.950000\n"
     ]
    }
   ],
   "source": [
    "best_model = training(model, loss_function, optimizer, one_cycle_scheduler, model_ready_data_creator, another_scheduler = reduce_lr_scheduler, num_epochs = epochs, start_epoch = start_epoch)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e33b35a3daf175164a8866caf84b1a28be75fe4033cda0d0df4e04a8e3008df4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('covid': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}